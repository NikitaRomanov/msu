{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "np.random.seed(123)\n",
    "from subprocess import check_output\n",
    "import xgboost as xgb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_folds = 5 #should be larger, but kaggle scirpts has run time \n",
    "\n",
    "def MAE(y,dtrain):\n",
    "    answer = dtrain.get_label()\n",
    "    answer = np.array(answer)\n",
    "    prediction = np.array(y)\n",
    "    error = np.exp(prediction) -np.exp(answer)\n",
    "    error = np.mean((error**2)**.5)\n",
    "    return 'mcc error',error\n",
    "    \n",
    "def MAE2(y,dtrain):\n",
    "    answer = dtrain.loss2\n",
    "    answer = np.array(answer)\n",
    "    prediction = np.array(y)\n",
    "    error = prediction - answer\n",
    "    error = np.mean((error**2)**.5)\n",
    "    return 'mcc error',error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## smaller dataset for faster training ###\n",
    "train=pd.read_csv(r'D:\\allstate\\train.csv.zip')\n",
    "test=pd.read_csv(r'D:\\allstate\\test.csv.zip')\n",
    "train['loss']=np.log(train['loss']+200)\n",
    "train['loss2']=np.exp(train['loss'])-200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## encode cat variables as discrete integers \n",
    "for i in list(train.keys()):\n",
    "\tif 'cat' in i:\n",
    "\t\tdictt = {}\n",
    "\t\tvar = sorted(list(train[i].unique()))\n",
    "\t\tfor ii in range(0,len(var)):\n",
    "\t\t\tdictt[var[ii]]=ii\n",
    "\t\ttrain[i] = train[i].map(dictt)\n",
    "\t\ttest[i] = test[i].map(dictt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188318, 133)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters =[]\n",
    "for i in (10,12):\n",
    "    for j in (90,):\n",
    "            for l in (1,2):\n",
    "                depth = i\n",
    "                min_child_weight = j\n",
    "                gamma=l\n",
    "                parameters += [[depth,min_child_weight,gamma],]\n",
    "predictors = ['cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9', 'cat10', 'cat11', 'cat12', \n",
    "              'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18', 'cat19', 'cat20', 'cat21', 'cat22', 'cat23', \n",
    "              'cat24', 'cat25', 'cat26', 'cat27', 'cat28', 'cat29', 'cat30', 'cat31', 'cat32', 'cat33', 'cat34', \n",
    "              'cat35', 'cat36', 'cat37', 'cat38', 'cat39', 'cat40', 'cat41', 'cat42', 'cat43', 'cat44', 'cat45', \n",
    "              'cat46', 'cat47', 'cat48', 'cat49', 'cat50', 'cat51', 'cat52', 'cat53', 'cat54', 'cat55', 'cat56', \n",
    "              'cat57', 'cat58', 'cat59', 'cat60', 'cat61', 'cat62', 'cat63', 'cat64', 'cat65', 'cat66', 'cat67', \n",
    "              'cat68', 'cat69', 'cat70', 'cat71', 'cat72', 'cat73', 'cat74', 'cat75', 'cat76', 'cat77', 'cat78', \n",
    "              'cat79', 'cat80', 'cat81', 'cat82', 'cat83', 'cat84', 'cat85', 'cat86', 'cat87', 'cat88', 'cat89', \n",
    "              'cat90', 'cat91', 'cat92', 'cat93', 'cat94', 'cat95', 'cat96', 'cat97', 'cat98', 'cat99', 'cat100', \n",
    "              'cat101', 'cat102', 'cat103', 'cat104', 'cat105', 'cat106', 'cat107', 'cat108', 'cat109', 'cat110', \n",
    "              'cat111', 'cat112', 'cat113', 'cat114', 'cat115', 'cat116', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5',\n",
    "              'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14']\n",
    "target='loss'\n",
    "result={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training  parameters 10 90 1 ,fold 0\n",
      "train_result ('mcc error', 1166.1108)\n",
      "\n",
      "training  parameters 10 90 1 ,fold 1\n",
      "train_result ('mcc error', 1178.5752)\n",
      "\n",
      "training  parameters 10 90 1 ,fold 2\n",
      "train_result ('mcc error', 1176.4307)\n",
      "\n",
      "training  parameters 10 90 1 ,fold 3\n",
      "train_result ('mcc error', 1185.2355)\n",
      "\n",
      "training  parameters 10 90 1 ,fold 4\n",
      "train_result ('mcc error', 1181.4565)\n",
      "\n",
      "training  parameters 10 90 2 ,fold 0\n",
      "train_result ('mcc error', 1169.5865)\n",
      "\n",
      "training  parameters 10 90 2 ,fold 1\n",
      "train_result ('mcc error', 1181.7942)\n",
      "\n",
      "training  parameters 10 90 2 ,fold 2\n",
      "train_result ('mcc error', 1178.6757)\n",
      "\n",
      "training  parameters 10 90 2 ,fold 3\n",
      "train_result ('mcc error', 1188.8602)\n",
      "\n",
      "training  parameters 10 90 2 ,fold 4\n",
      "train_result ('mcc error', 1184.651)\n",
      "\n",
      "training  parameters 12 90 1 ,fold 0\n",
      "train_result ('mcc error', 1161.5972)\n",
      "\n",
      "training  parameters 12 90 1 ,fold 1\n",
      "train_result ('mcc error', 1175.1838)\n",
      "\n",
      "training  parameters 12 90 1 ,fold 2\n",
      "train_result ('mcc error', 1172.6915)\n",
      "\n",
      "training  parameters 12 90 1 ,fold 3\n",
      "train_result ('mcc error', 1183.5101)\n",
      "\n",
      "training  parameters 12 90 1 ,fold 4\n",
      "train_result ('mcc error', 1179.5637)\n",
      "\n",
      "training  parameters 12 90 2 ,fold 0\n",
      "train_result ('mcc error', 1164.0619)\n",
      "\n",
      "training  parameters 12 90 2 ,fold 1\n",
      "train_result ('mcc error', 1179.0909)\n",
      "\n",
      "training  parameters 12 90 2 ,fold 2\n",
      "train_result ('mcc error', 1176.2937)\n",
      "\n",
      "training  parameters 12 90 2 ,fold 3\n",
      "train_result ('mcc error', 1187.0109)\n",
      "\n",
      "training  parameters 12 90 2 ,fold 4\n",
      "train_result ('mcc error', 1181.9171)\n"
     ]
    }
   ],
   "source": [
    "## train 4 models with different paremeters ###\n",
    "for i,j,l in parameters:\n",
    "    xgtest=xgb.DMatrix(test[predictors].values,missing=np.NAN,feature_names=predictors)\n",
    "    depth,min_child_weight,gamma=i,j,l\n",
    "    result[(depth,min_child_weight,gamma)]=[]\n",
    "    ### name of prediction ###\n",
    "    name = 'feature_L2_%s_%s_%s_%s' %(str(depth), str(min_child_weight), str(gamma),str(num_folds))\n",
    "    train[name]=0\n",
    "    test[name]=0\n",
    "    for fold in range(0,num_folds):\n",
    "        print ('\\ntraining  parameters', i,j,l,',fold',fold)\n",
    "        gc.collect() #to clear ram of garbage\n",
    "        train_i = [x for x in train.index if x%num_folds != fold]\n",
    "        cv_i = [x for x in train.index if x%num_folds == fold]\n",
    "        dtrain= train.iloc[train_i]\n",
    "        dcv = train.iloc[cv_i]\n",
    "        xgcv    = xgb.DMatrix(dcv[predictors].values, label=dcv[target].values,missing=np.NAN,feature_names=predictors)\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values,missing=np.NAN,feature_names=predictors)\n",
    "        #watchlist  = [ (xgtrain,'train'),(xgcv,'eval')] #i got valueerror in this\n",
    "        params = {}\n",
    "        params[\"objective\"] =  \"reg:linear\"\n",
    "        params[\"eta\"] = 0.1\n",
    "        params[\"min_child_weight\"] = min_child_weight\n",
    "        params[\"subsample\"] = 0.5\n",
    "        params[\"colsample_bytree\"] = 0.5\n",
    "        params[\"scale_pos_weight\"] = 1.0\n",
    "        params[\"silent\"] = 1\n",
    "        params[\"max_depth\"] = depth\n",
    "        params['seed']=1\n",
    "        params['lambda']=1\n",
    "        params[ 'gamma']= gamma\n",
    "        plst = list(params.items())\n",
    "        early_stopping_rounds=5\n",
    "        result_d=xgb.train(plst,xgtrain,50,maximize=0,feval = MAE)\n",
    "        #print (result_d.predict(xgcv))\n",
    "        print ('train_result',MAE(result_d.predict(xgcv),xgcv))\n",
    "        ### write predictions onto train and test set ###\n",
    "        train.set_value(cv_i,name,np.exp(result_d.predict(xgcv))-200)\n",
    "        test.set_value(test.index,name,test[name]+(np.exp(result_d.predict(xgtest)-200)/num_folds))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features are these: ['feature_L2_10_90_1_5', 'feature_L2_10_90_2_5', 'feature_L2_12_90_1_5', 'feature_L2_12_90_2_5']\n"
     ]
    }
   ],
   "source": [
    "#### NOW THE MCMC PART to find individal weights for ensemble####\n",
    "\n",
    "features = [x for x in  train.keys() if 'feature' in x]\n",
    "print ('features are these:', features)\n",
    "num=len(features)\n",
    "#intialize weights\n",
    "weight = np.array([1.0/num,]*num)\n",
    "\n",
    "# This is to define variables to be used later\n",
    "train['pred_new']=0\n",
    "train['pred_old']=0\n",
    "counter = 0\n",
    "n=1000 ###MCMC steps\n",
    "result={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: feature_L2_10_90_1_5 ,MAE= ('mcc error', 1177.5617107683111)\n",
      "feature: feature_L2_10_90_2_5 ,MAE= ('mcc error', 1180.7134440113846)\n",
      "feature: feature_L2_12_90_1_5 ,MAE= ('mcc error', 1174.5092199062833)\n",
      "feature: feature_L2_12_90_2_5 ,MAE= ('mcc error', 1177.6748000042724)\n",
      "combined all features ,MAE= ('mcc error', 1175.677680020571)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(features)):\n",
    "    train['pred_new'] += train[features[i]]*weight[i]\n",
    "    print ('feature:',features[i],',MAE=',MAE2(train[features[i]],train))\n",
    "print ('combined all features',',MAE=', MAE2(train.pred_new,train))\n",
    "train['pred_old']=train['pred_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.645 Acceptance Ratio\n",
      "best result MAE (1162.9731769449163, 1162.9731769449163, 1, 0.8438624432218227, array([ 0.19203593,  0.227896  ,  0.3853734 ,  0.27050085]))\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,n):\n",
    "    new_weights = weight + np.array([0.005,]*num)*np.random.normal(loc=0.0, scale=1.0, size=num)\n",
    "    new_weights[new_weights < 0.01]=0.01\n",
    "    train['pred_new']=0\n",
    "    for ii in range(0,len(features)):\n",
    "        train['pred_new'] += train[features[ii]]*new_weights[ii]\n",
    "    diff = MAE2(train.pred_new,train)[1] - MAE2(train.pred_old,train)[1]\n",
    "    prob = min(1,np.exp(-diff/.3))\n",
    "    random_prob = np.random.rand()\n",
    "    if random_prob < prob:\n",
    "        weight= new_weights\n",
    "        train['pred_old']=train['pred_new']\n",
    "        result[i] = (MAE2(train.pred_new,train)[1] ,MAE2(train.pred_old,train)[1],prob,random_prob ,weight)\n",
    "        #print (MAE2(train.pred_new,train)[1] ,MAE2(train.pred_old,train)[1],prob,random_prob),\n",
    "        counter +=1\n",
    "print (counter *1.0 / n, 'Acceptance Ratio') #keep this [0.4,0.6] for best results\n",
    "print ('best result MAE', sorted([result[i] for i in result])[0:1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined all features plus MCMC weights: , MAE= ('mcc error', 5887794.2653777171)\n",
      "weights: [ 0.19203593  0.227896    0.3853734   0.27050085]\n"
     ]
    }
   ],
   "source": [
    "weight=sorted([result[i] for i in result])[0:1][-1]\n",
    "train['pred_new']=0\n",
    "for i in range(0,len(features)):\n",
    "    train['pred_new'] += train[features[i]]*weight[i]\n",
    "print ('combined all features plus MCMC weights:',', MAE=', MAE2(train.pred_new,train))\n",
    "\n",
    "print ('weights:', weight[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined all features plus MCMC weights: , MAE= ('mcc error', 5850208.6873818878)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
