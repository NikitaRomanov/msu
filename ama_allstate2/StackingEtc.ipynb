{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple examples of ensembling models\n",
    "\n",
    "Expected that hyperparameters of base models are already tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SHIFT = 190\n",
    "os.environ['LIGHTGBM_EXEC'] = r'D:\\LightGBM\\LightGBM\\windows\\x64\\Release\\lightgbm.exe'  # path to LightGBM executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [01:03<00:00,  2.06it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\allstate\\train.csv.zip', compression='zip')\n",
    "\n",
    "for column in tqdm(df.columns):\n",
    "    encoder = LabelEncoder()\n",
    "    if column.startswith('cat') :\n",
    "        df[column] = encoder.fit_transform(df[column])\n",
    "        df['{}_sz'.format(column)] = df[column].map(df.groupby(column).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cat107_sz</th>\n",
       "      <th>cat108_sz</th>\n",
       "      <th>cat109_sz</th>\n",
       "      <th>cat110_sz</th>\n",
       "      <th>cat111_sz</th>\n",
       "      <th>cat112_sz</th>\n",
       "      <th>cat113_sz</th>\n",
       "      <th>cat114_sz</th>\n",
       "      <th>cat115_sz</th>\n",
       "      <th>cat116_sz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>22405</td>\n",
       "      <td>21421</td>\n",
       "      <td>3142</td>\n",
       "      <td>4131</td>\n",
       "      <td>32401</td>\n",
       "      <td>17669</td>\n",
       "      <td>7033</td>\n",
       "      <td>131693</td>\n",
       "      <td>26813</td>\n",
       "      <td>3194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20236</td>\n",
       "      <td>42435</td>\n",
       "      <td>152918</td>\n",
       "      <td>3271</td>\n",
       "      <td>128395</td>\n",
       "      <td>7122</td>\n",
       "      <td>26191</td>\n",
       "      <td>131693</td>\n",
       "      <td>26813</td>\n",
       "      <td>9202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>47310</td>\n",
       "      <td>9299</td>\n",
       "      <td>21933</td>\n",
       "      <td>1745</td>\n",
       "      <td>128395</td>\n",
       "      <td>2257</td>\n",
       "      <td>6079</td>\n",
       "      <td>131693</td>\n",
       "      <td>7090</td>\n",
       "      <td>2632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20236</td>\n",
       "      <td>42435</td>\n",
       "      <td>152918</td>\n",
       "      <td>24592</td>\n",
       "      <td>32401</td>\n",
       "      <td>8453</td>\n",
       "      <td>22030</td>\n",
       "      <td>131693</td>\n",
       "      <td>26813</td>\n",
       "      <td>20244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>28560</td>\n",
       "      <td>65512</td>\n",
       "      <td>73</td>\n",
       "      <td>2681</td>\n",
       "      <td>32401</td>\n",
       "      <td>1351</td>\n",
       "      <td>26191</td>\n",
       "      <td>131693</td>\n",
       "      <td>43866</td>\n",
       "      <td>10162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9    ...      \\\n",
       "0   1     0     1     0     1     0     0     0     0     1    ...       \n",
       "1   2     0     1     0     0     0     0     0     0     1    ...       \n",
       "2   5     0     1     0     0     1     0     0     0     1    ...       \n",
       "3  10     1     1     0     1     0     0     0     0     1    ...       \n",
       "4  11     0     1     0     1     0     0     0     0     1    ...       \n",
       "\n",
       "   cat107_sz  cat108_sz  cat109_sz  cat110_sz  cat111_sz  cat112_sz  \\\n",
       "0      22405      21421       3142       4131      32401      17669   \n",
       "1      20236      42435     152918       3271     128395       7122   \n",
       "2      47310       9299      21933       1745     128395       2257   \n",
       "3      20236      42435     152918      24592      32401       8453   \n",
       "4      28560      65512         73       2681      32401       1351   \n",
       "\n",
       "   cat113_sz  cat114_sz  cat115_sz  cat116_sz  \n",
       "0       7033     131693      26813       3194  \n",
       "1      26191     131693      26813       9202  \n",
       "2       6079     131693       7090       2632  \n",
       "3      22030     131693      26813      20244  \n",
       "4      26191     131693      43866      10162  \n",
       "\n",
       "[5 rows x 248 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### For speed and simplicity there are only one split 80% / 20%\n",
    "This is equivalent to a single iteration of 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.2, random_state = 0)\n",
    "y_train, y_test = train['loss'], test['loss']\n",
    "del train['loss'], test['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit simple XGBoost and LightGBM models (without any tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1162.57690233\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain = xgb.DMatrix(train, label=np.log(y_train + SHIFT))\n",
    "dtest = xgb.DMatrix(test)\n",
    "params = {'silent': 1}\n",
    "model = xgb.train(params, dtrain, 100)\n",
    "y_pred_1 = np.exp(model.predict(dtest)) - SHIFT\n",
    "print(mean_absolute_error(y_pred_1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150.51258449\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pylightgbm.models import GBMRegressor\n",
    "params = {'verbose': False, 'num_iterations': 100}\n",
    "clf = GBMRegressor(**params)\n",
    "clf.fit(train, np.log(y_train + SHIFT))\n",
    "y_pred_2 = np.exp(clf.predict(test)) - SHIFT\n",
    "print(mean_absolute_error(y_pred_2, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get mean of this predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1147.48434138\n"
     ]
    }
   ],
   "source": [
    "y_pred = (y_pred_1 + y_pred_2)/2\n",
    "print(mean_absolute_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Try to choose weights for convex combination of predictions\n",
    "i.e the sum of the weights is equal to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 1149.34982513\n",
      "0.1 1148.40174425\n",
      "0.15 1147.62488821\n",
      "0.2 1147.04778303\n",
      "0.25 1146.6589999\n",
      "0.3 1146.46163812\n",
      "0.35 1146.45360075\n",
      "0.4 1146.60493836\n",
      "0.45 1146.94584922\n",
      "0.5 1147.48434138\n",
      "0.55 1148.19759288\n",
      "0.6 1149.10182459\n",
      "0.65 1150.15430338\n",
      "0.7 1151.38349634\n",
      "0.75 1152.79689637\n",
      "0.8 1154.37413736\n",
      "0.85 1156.14686535\n",
      "0.9 1158.13413016\n",
      "0.95 1160.27132575\n",
      "----------------\n",
      "best: 0.35 1146.45360075\n"
     ]
    }
   ],
   "source": [
    "best_a = None\n",
    "min_err = 10**6\n",
    "for a in np.arange(.05, 1, .05):\n",
    "    y_pred = a*y_pred_1 + (1 - a)*y_pred_2\n",
    "    err = mean_absolute_error(y_pred, y_test)\n",
    "    if err < min_err:\n",
    "        min_err = err\n",
    "        best_a = a\n",
    "    print(a, err)\n",
    "print('----------------')\n",
    "print('best:', best_a, min_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is better than simple mean.\n",
    "\n",
    "When using such method better models will have larger weight. This can be a problem if you have models with different quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get out of fold predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from pylightgbm.models import GBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "N_SPLITS = 5\n",
    "\n",
    "def get_xgb_pred(X_train, X_test, y_train, params=None, n_trees=100, res_transform=None):\n",
    "    if params is None:\n",
    "        params = {'silent': 1}\n",
    "    if res_transform is None:\n",
    "        res_transform = lambda x: x\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    model = xgb.train(params, dtrain, n_trees)\n",
    "    return res_transform(model.predict(dtest))\n",
    "\n",
    "def get_lightgbm_pred(X_train, X_test, y_train, params=None, n_trees=100, res_transform=None):\n",
    "    if params is None:\n",
    "        params = {'verbose': False}\n",
    "    if not 'num_iterations' in params:\n",
    "        params['num_iterations'] = n_trees\n",
    "    if res_transform is None:\n",
    "        res_transform = lambda x: x\n",
    "    clf = GBMRegressor(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return res_transform(clf.predict(X_test))\n",
    "\n",
    "def predict_outoffolds(X, y, X_test=None, func='get_xgb_pred', params=None, res_transform=None, n_splits=3):\n",
    "    if X_test is None:\n",
    "        kf = KFold(n_splits=n_splits)\n",
    "        y_pred = np.zeros_like(y.values)\n",
    "        for train_inds, test_inds in kf.split(X):\n",
    "            y_pred[test_inds] = globals()[func](X.iloc[train_inds], X.iloc[test_inds],\n",
    "                                                y.iloc[train_inds], res_transform=res_transform, params=params)\n",
    "        return y_pred\n",
    "    else:\n",
    "        return globals()[func](X, X_test, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_stack = pd.DataFrame(index=train.index)\n",
    "test_stack = pd.DataFrame(index=test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_stack['y_xgb'] = predict_outoffolds(train, np.log(y_train + SHIFT), func='get_xgb_pred')\n",
    "test_stack['y_xgb'] = predict_outoffolds(train, np.log(y_train + SHIFT), X_test=test, func='get_xgb_pred')\n",
    "\n",
    "train_stack['y_lightgbm'] = predict_outoffolds(train, np.log(y_train + SHIFT), func='get_lightgbm_pred')\n",
    "test_stack['y_lightgbm'] = predict_outoffolds(train, np.log(y_train + SHIFT), X_test=test, func='get_lightgbm_pred')\n",
    "\n",
    "train_stack['y_xgb'] = np.exp(train_stack.y_xgb) - SHIFT\n",
    "test_stack['y_xgb'] = np.exp(test_stack.y_xgb) - SHIFT\n",
    "\n",
    "train_stack['y_lightgbm'] = np.exp(train_stack.y_lightgbm) - SHIFT\n",
    "test_stack['y_lightgbm'] = np.exp(test_stack.y_lightgbm) - SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168.72249866 1149.18904792 1162.57690233 1150.51258449\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(train_stack.y_xgb.fillna(0), y_train),\n",
    "      mean_absolute_error(train_stack.y_lightgbm.fillna(0), y_train),\n",
    "      mean_absolute_error(test_stack.y_xgb.fillna(0), y_test),\n",
    "      mean_absolute_error(test_stack.y_lightgbm.fillna(0), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit linear regression without bias on this two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166.85276723\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(fit_intercept=False)\n",
    "lr.fit(train_stack[['y_xgb', 'y_lightgbm']], y_train)\n",
    "y_pred = lr.predict(test_stack[['y_xgb', 'y_lightgbm']])\n",
    "print(mean_absolute_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.420327063731 0.693043542054\n"
     ]
    }
   ],
   "source": [
    "print(*lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit nonlinear model on second level\n",
    "concatenate meta features with original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_train = pd.concat([train, train_stack], axis=1)\n",
    "_test = pd.concat([test, test_stack], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145.86787888\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pylightgbm.models import GBMRegressor\n",
    "params = {'verbose': False, 'num_iterations': 100}\n",
    "clf = GBMRegressor(**params)\n",
    "clf.fit(_train, np.log(y_train + SHIFT))\n",
    "y_pred = np.exp(clf.predict(_test)) - SHIFT\n",
    "print(mean_absolute_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better than convex combination of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Try to add yet another LightGBM\n",
    "parameters are intentionally set to non-optimal values to get a weaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1163.78679666\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {\n",
    "    'num_iterations': 100,\n",
    "    'num_leaves': 127,\n",
    "    'feature_fraction': .5,\n",
    "    'bagging_fraction': .5,\n",
    "    'learning_rate': .06,\n",
    "    'min_data_in_leaf': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "from pylightgbm.models import GBMRegressor\n",
    "clf = GBMRegressor(**params)\n",
    "clf.fit(train, np.log(y_train + SHIFT))\n",
    "y_pred_3 = np.exp(clf.predict(test)) - SHIFT\n",
    "print(mean_absolute_error(y_pred_3, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148.27363456\n"
     ]
    }
   ],
   "source": [
    "y_pred = (y_pred_1 + y_pred_2 + y_pred_3)/3\n",
    "print(mean_absolute_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weak model worsened the result of averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convex combination of predictions tuned by Sequential Least Squares Programming solver\n",
    "https://github.com/jdwittenauer/kaggle/blob/master/OttoGroup/find_ensemble_weights.py\n",
    "\n",
    "http://stackoverflow.com/questions/35631192/element-wise-constraints-in-scipy-optimize-minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "def log_loss_func(weights):\n",
    "    \"\"\"\n",
    "    scipy minimize will pass the weights as a numpy array\n",
    "    \"\"\"\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, preds):\n",
    "            final_prediction += weight*prediction\n",
    "    return mean_absolute_error(y_test, final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = [y_pred_1, y_pred_2, y_pred_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_weights = np.ones(len(preds)) / len(preds)\n",
    "# adding constraints\n",
    "cons = ({'type': 'eq', 'fun': lambda w: 1-sum(w)})  # weights are sum to 1\n",
    "bounds = [(0, 1)] * len(preds)  # and bounded between 0 and 1\n",
    "w = minimize(log_loss_func, init_weights, method='SLSQP', bounds=bounds, constraints=cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3332174,  0.3332174,  0.3335652])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1148.2759080673209"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(np.dot(w.x.reshape(1, -1), np.vstack([y_pred_1, y_pred_2, y_pred_3])).ravel(), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better than simple mean, but it is not the general case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get out-of-fold prediction for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_stack['y_lightgbm2'] = predict_outoffolds(train, np.log(y_train + SHIFT), func='get_lightgbm_pred', params=params)\n",
    "test_stack['y_lightgbm2'] = predict_outoffolds(train, np.log(y_train + SHIFT), X_test=test, func='get_lightgbm_pred',\n",
    "                                               params=params)\n",
    "\n",
    "train_stack['y_lightgbm2'] = np.exp(train_stack.y_lightgbm2) - SHIFT\n",
    "test_stack['y_lightgbm2'] = np.exp(test_stack.y_lightgbm2) - SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158.31610102 1150.51258449\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(train_stack.y_lightgbm2.fillna(0), y_train),\n",
    "      mean_absolute_error(test_stack.y_lightgbm2.fillna(0), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit nonlinear model on second level\n",
    "concatenate meta features with original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_train = pd.concat([train, train_stack], axis=1)\n",
    "_test = pd.concat([test, test_stack], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145.41550548\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'verbose': False, 'num_iterations': 100, 'num_leaves': 63}\n",
    "clf = GBMRegressor(**params)\n",
    "clf.fit(_train, np.log(y_train + SHIFT), test_data=[(_test, np.log(y_test + SHIFT))])\n",
    "y_pred = np.exp(clf.predict(_test)) - SHIFT\n",
    "print(mean_absolute_error(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Some links\n",
    "http://mlwave.com/kaggle-ensembling-guide/\n",
    "\n",
    "https://www.kaggle.com/c/allstate-claims-severity/forums/t/25743/stacking-understanding-python-package-for-stacking\n",
    "\n",
    "https://www.kaggle.com/c/allstate-claims-severity/forums/t/25240/weights-in-an-ensemble"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
