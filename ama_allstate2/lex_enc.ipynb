{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import skew, boxcox\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift = 200\n",
    "COMB_FEATURE = 'cat80,cat87,cat57,cat12,cat79,cat10,cat7,cat89,cat2,cat72,cat81,cat11,cat1,cat13,cat9,cat3,cat16,cat90,cat23,cat36,cat73,cat103,cat40,cat28,cat111,cat6,cat76,cat50,cat5,cat4,cat14,cat38,cat24,cat82,cat25'.split(\n",
    "    ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(charcode):\n",
    "    r = 0\n",
    "    if(type(charcode) is float):\n",
    "        return np.nan\n",
    "    else:\n",
    "        ln = len(charcode)\n",
    "        for i in range(ln):\n",
    "            r += (ord(charcode[i]) - ord('A') + 1) * 26 ** (ln - i - 1)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    con = 2\n",
    "    x = preds - labels\n",
    "    grad = con * x / (np.abs(x) + con)\n",
    "    hess = con ** 2 / (np.abs(x) + con) ** 2\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y) - shift,\n",
    "                                      np.exp(yhat) - shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mungeskewed(train, test, numeric_feats):\n",
    "    ntrain = train.shape[0]\n",
    "    test['loss'] = 0\n",
    "    train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "    # compute skew and do Box-Cox transformation (Tilli)\n",
    "    skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "    print(\"\\nSkew in numeric features:\")\n",
    "    print(skewed_feats)\n",
    "    skewed_feats = skewed_feats[skewed_feats > 0.25]\n",
    "    skewed_feats = skewed_feats.index\n",
    "\n",
    "    for feats in skewed_feats:\n",
    "        train_test[feats] = train_test[feats] + 1\n",
    "        train_test[feats], lam = boxcox(train_test[feats])\n",
    "    return train_test, ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n",
      "\n",
      "Skew in numeric features:\n",
      "cont1     0.516420\n",
      "cont2    -0.310939\n",
      "cont3    -0.010002\n",
      "cont4     0.416093\n",
      "cont5     0.681617\n",
      "cont6     0.461211\n",
      "cont7     0.826046\n",
      "cont8     0.676629\n",
      "cont9     1.072420\n",
      "cont10    0.354998\n",
      "cont11    0.280819\n",
      "cont12    0.291990\n",
      "cont13    0.380739\n",
      "cont14    0.248672\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Started')\n",
    "train = pd.read_csv(r'D:\\allstate\\train.csv.zip')\n",
    "test = pd.read_csv(r'D:\\allstate\\test.csv.zip')\n",
    "numeric_feats = [x for x in train.columns[1:-1] if 'cont' in x]\n",
    "cats = [x for x in train.columns[1:-1] if 'cat' in x]\n",
    "train_test, ntrain = mungeskewed(train, test, numeric_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    if train[column].nunique() != test[column].nunique():\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        remove_train = set_train - set_test\n",
    "        remove_test = set_test - set_train\n",
    "\n",
    "        remove = remove_train.union(remove_test)\n",
    "\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "\n",
    "        train_test[column] = train_test[column].apply(lambda x: filter_cat(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test[\"cont1\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont1\"]))\n",
    "train_test[\"cont4\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont4\"]))\n",
    "train_test[\"cont5\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont5\"]))\n",
    "train_test[\"cont8\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont8\"]))\n",
    "train_test[\"cont10\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont10\"]))\n",
    "train_test[\"cont11\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont11\"]))\n",
    "train_test[\"cont12\"] = np.sqrt(preprocessing.minmax_scale(train_test[\"cont12\"]))\n",
    "\n",
    "train_test[\"cont6\"] = np.log(preprocessing.minmax_scale(train_test[\"cont6\"]) + 0000.1)\n",
    "train_test[\"cont7\"] = np.log(preprocessing.minmax_scale(train_test[\"cont7\"]) + 0000.1)\n",
    "train_test[\"cont9\"] = np.log(preprocessing.minmax_scale(train_test[\"cont9\"]) + 0000.1)\n",
    "train_test[\"cont13\"] = np.log(preprocessing.minmax_scale(train_test[\"cont13\"]) + 0000.1)\n",
    "train_test[\"cont14\"] = (np.maximum(train_test[\"cont14\"] - 0.179722, 0) / 0.665122) ** 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat80_cat87\n",
      "cat80_cat57\n",
      "cat80_cat12\n",
      "cat80_cat79\n",
      "cat80_cat10\n",
      "cat80_cat7\n",
      "cat80_cat89\n",
      "cat80_cat2\n",
      "cat80_cat72\n",
      "cat80_cat81\n",
      "cat80_cat11\n",
      "cat80_cat1\n",
      "cat80_cat13\n",
      "cat80_cat9\n",
      "cat80_cat3\n",
      "cat80_cat16\n",
      "cat80_cat90\n",
      "cat80_cat23\n",
      "cat80_cat36\n",
      "cat80_cat73\n",
      "cat80_cat103\n",
      "cat80_cat40\n",
      "cat80_cat28\n",
      "cat80_cat111\n",
      "cat80_cat6\n",
      "cat80_cat76\n",
      "cat80_cat50\n",
      "cat80_cat5\n",
      "cat80_cat4\n",
      "cat80_cat14\n",
      "cat80_cat38\n",
      "cat80_cat24\n",
      "cat80_cat82\n",
      "cat80_cat25\n",
      "cat87_cat57\n",
      "cat87_cat12\n",
      "cat87_cat79\n",
      "cat87_cat10\n",
      "cat87_cat7\n",
      "cat87_cat89\n",
      "cat87_cat2\n",
      "cat87_cat72\n",
      "cat87_cat81\n",
      "cat87_cat11\n",
      "cat87_cat1\n",
      "cat87_cat13\n",
      "cat87_cat9\n",
      "cat87_cat3\n",
      "cat87_cat16\n",
      "cat87_cat90\n",
      "cat87_cat23\n",
      "cat87_cat36\n",
      "cat87_cat73\n",
      "cat87_cat103\n",
      "cat87_cat40\n",
      "cat87_cat28\n",
      "cat87_cat111\n",
      "cat87_cat6\n",
      "cat87_cat76\n",
      "cat87_cat50\n",
      "cat87_cat5\n",
      "cat87_cat4\n",
      "cat87_cat14\n",
      "cat87_cat38\n",
      "cat87_cat24\n",
      "cat87_cat82\n",
      "cat87_cat25\n",
      "cat57_cat12\n",
      "cat57_cat79\n",
      "cat57_cat10\n",
      "cat57_cat7\n",
      "cat57_cat89\n",
      "cat57_cat2\n",
      "cat57_cat72\n",
      "cat57_cat81\n",
      "cat57_cat11\n",
      "cat57_cat1\n",
      "cat57_cat13\n",
      "cat57_cat9\n",
      "cat57_cat3\n",
      "cat57_cat16\n",
      "cat57_cat90\n",
      "cat57_cat23\n",
      "cat57_cat36\n",
      "cat57_cat73\n",
      "cat57_cat103\n",
      "cat57_cat40\n",
      "cat57_cat28\n",
      "cat57_cat111\n",
      "cat57_cat6\n",
      "cat57_cat76\n",
      "cat57_cat50\n",
      "cat57_cat5\n",
      "cat57_cat4\n",
      "cat57_cat14\n",
      "cat57_cat38\n",
      "cat57_cat24\n",
      "cat57_cat82\n",
      "cat57_cat25\n",
      "cat12_cat79\n",
      "cat12_cat10\n",
      "cat12_cat7\n",
      "cat12_cat89\n",
      "cat12_cat2\n",
      "cat12_cat72\n",
      "cat12_cat81\n",
      "cat12_cat11\n",
      "cat12_cat1\n",
      "cat12_cat13\n",
      "cat12_cat9\n",
      "cat12_cat3\n",
      "cat12_cat16\n",
      "cat12_cat90\n",
      "cat12_cat23\n",
      "cat12_cat36\n",
      "cat12_cat73\n",
      "cat12_cat103\n",
      "cat12_cat40\n",
      "cat12_cat28\n",
      "cat12_cat111\n",
      "cat12_cat6\n",
      "cat12_cat76\n",
      "cat12_cat50\n",
      "cat12_cat5\n",
      "cat12_cat4\n",
      "cat12_cat14\n",
      "cat12_cat38\n",
      "cat12_cat24\n",
      "cat12_cat82\n",
      "cat12_cat25\n",
      "cat79_cat10\n",
      "cat79_cat7\n",
      "cat79_cat89\n",
      "cat79_cat2\n",
      "cat79_cat72\n",
      "cat79_cat81\n",
      "cat79_cat11\n",
      "cat79_cat1\n",
      "cat79_cat13\n",
      "cat79_cat9\n",
      "cat79_cat3\n",
      "cat79_cat16\n",
      "cat79_cat90\n",
      "cat79_cat23\n",
      "cat79_cat36\n",
      "cat79_cat73\n",
      "cat79_cat103\n",
      "cat79_cat40\n",
      "cat79_cat28\n",
      "cat79_cat111\n",
      "cat79_cat6\n",
      "cat79_cat76\n",
      "cat79_cat50\n",
      "cat79_cat5\n",
      "cat79_cat4\n",
      "cat79_cat14\n",
      "cat79_cat38\n",
      "cat79_cat24\n",
      "cat79_cat82\n",
      "cat79_cat25\n",
      "cat10_cat7\n",
      "cat10_cat89\n",
      "cat10_cat2\n",
      "cat10_cat72\n",
      "cat10_cat81\n",
      "cat10_cat11\n",
      "cat10_cat1\n",
      "cat10_cat13\n",
      "cat10_cat9\n",
      "cat10_cat3\n",
      "cat10_cat16\n",
      "cat10_cat90\n",
      "cat10_cat23\n",
      "cat10_cat36\n",
      "cat10_cat73\n",
      "cat10_cat103\n",
      "cat10_cat40\n",
      "cat10_cat28\n",
      "cat10_cat111\n",
      "cat10_cat6\n",
      "cat10_cat76\n",
      "cat10_cat50\n",
      "cat10_cat5\n",
      "cat10_cat4\n",
      "cat10_cat14\n",
      "cat10_cat38\n",
      "cat10_cat24\n",
      "cat10_cat82\n",
      "cat10_cat25\n",
      "cat7_cat89\n",
      "cat7_cat2\n",
      "cat7_cat72\n",
      "cat7_cat81\n",
      "cat7_cat11\n",
      "cat7_cat1\n",
      "cat7_cat13\n",
      "cat7_cat9\n",
      "cat7_cat3\n",
      "cat7_cat16\n",
      "cat7_cat90\n",
      "cat7_cat23\n",
      "cat7_cat36\n",
      "cat7_cat73\n",
      "cat7_cat103\n",
      "cat7_cat40\n",
      "cat7_cat28\n",
      "cat7_cat111\n",
      "cat7_cat6\n",
      "cat7_cat76\n",
      "cat7_cat50\n",
      "cat7_cat5\n",
      "cat7_cat4\n",
      "cat7_cat14\n",
      "cat7_cat38\n",
      "cat7_cat24\n",
      "cat7_cat82\n",
      "cat7_cat25\n",
      "cat89_cat2\n",
      "cat89_cat72\n",
      "cat89_cat81\n",
      "cat89_cat11\n",
      "cat89_cat1\n",
      "cat89_cat13\n",
      "cat89_cat9\n",
      "cat89_cat3\n",
      "cat89_cat16\n",
      "cat89_cat90\n",
      "cat89_cat23\n",
      "cat89_cat36\n",
      "cat89_cat73\n",
      "cat89_cat103\n",
      "cat89_cat40\n",
      "cat89_cat28\n",
      "cat89_cat111\n",
      "cat89_cat6\n",
      "cat89_cat76\n",
      "cat89_cat50\n",
      "cat89_cat5\n",
      "cat89_cat4\n",
      "cat89_cat14\n",
      "cat89_cat38\n",
      "cat89_cat24\n",
      "cat89_cat82\n",
      "cat89_cat25\n",
      "cat2_cat72\n",
      "cat2_cat81\n",
      "cat2_cat11\n",
      "cat2_cat1\n",
      "cat2_cat13\n",
      "cat2_cat9\n",
      "cat2_cat3\n",
      "cat2_cat16\n",
      "cat2_cat90\n",
      "cat2_cat23\n",
      "cat2_cat36\n",
      "cat2_cat73\n",
      "cat2_cat103\n",
      "cat2_cat40\n",
      "cat2_cat28\n",
      "cat2_cat111\n",
      "cat2_cat6\n",
      "cat2_cat76\n",
      "cat2_cat50\n",
      "cat2_cat5\n",
      "cat2_cat4\n",
      "cat2_cat14\n",
      "cat2_cat38\n",
      "cat2_cat24\n",
      "cat2_cat82\n",
      "cat2_cat25\n",
      "cat72_cat81\n",
      "cat72_cat11\n",
      "cat72_cat1\n",
      "cat72_cat13\n",
      "cat72_cat9\n",
      "cat72_cat3\n",
      "cat72_cat16\n",
      "cat72_cat90\n",
      "cat72_cat23\n",
      "cat72_cat36\n",
      "cat72_cat73\n",
      "cat72_cat103\n",
      "cat72_cat40\n",
      "cat72_cat28\n",
      "cat72_cat111\n",
      "cat72_cat6\n",
      "cat72_cat76\n",
      "cat72_cat50\n",
      "cat72_cat5\n",
      "cat72_cat4\n",
      "cat72_cat14\n",
      "cat72_cat38\n",
      "cat72_cat24\n",
      "cat72_cat82\n",
      "cat72_cat25\n",
      "cat81_cat11\n",
      "cat81_cat1\n",
      "cat81_cat13\n",
      "cat81_cat9\n",
      "cat81_cat3\n",
      "cat81_cat16\n",
      "cat81_cat90\n",
      "cat81_cat23\n",
      "cat81_cat36\n",
      "cat81_cat73\n",
      "cat81_cat103\n",
      "cat81_cat40\n",
      "cat81_cat28\n",
      "cat81_cat111\n",
      "cat81_cat6\n",
      "cat81_cat76\n",
      "cat81_cat50\n",
      "cat81_cat5\n",
      "cat81_cat4\n",
      "cat81_cat14\n",
      "cat81_cat38\n",
      "cat81_cat24\n",
      "cat81_cat82\n",
      "cat81_cat25\n",
      "cat11_cat1\n",
      "cat11_cat13\n",
      "cat11_cat9\n",
      "cat11_cat3\n",
      "cat11_cat16\n",
      "cat11_cat90\n",
      "cat11_cat23\n",
      "cat11_cat36\n",
      "cat11_cat73\n",
      "cat11_cat103\n",
      "cat11_cat40\n",
      "cat11_cat28\n",
      "cat11_cat111\n",
      "cat11_cat6\n",
      "cat11_cat76\n",
      "cat11_cat50\n",
      "cat11_cat5\n",
      "cat11_cat4\n",
      "cat11_cat14\n",
      "cat11_cat38\n",
      "cat11_cat24\n",
      "cat11_cat82\n",
      "cat11_cat25\n",
      "cat1_cat13\n",
      "cat1_cat9\n",
      "cat1_cat3\n",
      "cat1_cat16\n",
      "cat1_cat90\n",
      "cat1_cat23\n",
      "cat1_cat36\n",
      "cat1_cat73\n",
      "cat1_cat103\n",
      "cat1_cat40\n",
      "cat1_cat28\n",
      "cat1_cat111\n",
      "cat1_cat6\n",
      "cat1_cat76\n",
      "cat1_cat50\n",
      "cat1_cat5\n",
      "cat1_cat4\n",
      "cat1_cat14\n",
      "cat1_cat38\n",
      "cat1_cat24\n",
      "cat1_cat82\n",
      "cat1_cat25\n",
      "cat13_cat9\n",
      "cat13_cat3\n",
      "cat13_cat16\n",
      "cat13_cat90\n",
      "cat13_cat23\n",
      "cat13_cat36\n",
      "cat13_cat73\n",
      "cat13_cat103\n",
      "cat13_cat40\n",
      "cat13_cat28\n",
      "cat13_cat111\n",
      "cat13_cat6\n",
      "cat13_cat76\n",
      "cat13_cat50\n",
      "cat13_cat5\n",
      "cat13_cat4\n",
      "cat13_cat14\n",
      "cat13_cat38\n",
      "cat13_cat24\n",
      "cat13_cat82\n",
      "cat13_cat25\n",
      "cat9_cat3\n",
      "cat9_cat16\n",
      "cat9_cat90\n",
      "cat9_cat23\n",
      "cat9_cat36\n",
      "cat9_cat73\n",
      "cat9_cat103\n",
      "cat9_cat40\n",
      "cat9_cat28\n",
      "cat9_cat111\n",
      "cat9_cat6\n",
      "cat9_cat76\n",
      "cat9_cat50\n",
      "cat9_cat5\n",
      "cat9_cat4\n",
      "cat9_cat14\n",
      "cat9_cat38\n",
      "cat9_cat24\n",
      "cat9_cat82\n",
      "cat9_cat25\n",
      "cat3_cat16\n",
      "cat3_cat90\n",
      "cat3_cat23\n",
      "cat3_cat36\n",
      "cat3_cat73\n",
      "cat3_cat103\n",
      "cat3_cat40\n",
      "cat3_cat28\n",
      "cat3_cat111\n",
      "cat3_cat6\n",
      "cat3_cat76\n",
      "cat3_cat50\n",
      "cat3_cat5\n",
      "cat3_cat4\n",
      "cat3_cat14\n",
      "cat3_cat38\n",
      "cat3_cat24\n",
      "cat3_cat82\n",
      "cat3_cat25\n",
      "cat16_cat90\n",
      "cat16_cat23\n",
      "cat16_cat36\n",
      "cat16_cat73\n",
      "cat16_cat103\n",
      "cat16_cat40\n",
      "cat16_cat28\n",
      "cat16_cat111\n",
      "cat16_cat6\n",
      "cat16_cat76\n",
      "cat16_cat50\n",
      "cat16_cat5\n",
      "cat16_cat4\n",
      "cat16_cat14\n",
      "cat16_cat38\n",
      "cat16_cat24\n",
      "cat16_cat82\n",
      "cat16_cat25\n",
      "cat90_cat23\n",
      "cat90_cat36\n",
      "cat90_cat73\n",
      "cat90_cat103\n",
      "cat90_cat40\n",
      "cat90_cat28\n",
      "cat90_cat111\n",
      "cat90_cat6\n",
      "cat90_cat76\n",
      "cat90_cat50\n",
      "cat90_cat5\n",
      "cat90_cat4\n",
      "cat90_cat14\n",
      "cat90_cat38\n",
      "cat90_cat24\n",
      "cat90_cat82\n",
      "cat90_cat25\n",
      "cat23_cat36\n",
      "cat23_cat73\n",
      "cat23_cat103\n",
      "cat23_cat40\n",
      "cat23_cat28\n",
      "cat23_cat111\n",
      "cat23_cat6\n",
      "cat23_cat76\n",
      "cat23_cat50\n",
      "cat23_cat5\n",
      "cat23_cat4\n",
      "cat23_cat14\n",
      "cat23_cat38\n",
      "cat23_cat24\n",
      "cat23_cat82\n",
      "cat23_cat25\n",
      "cat36_cat73\n",
      "cat36_cat103\n",
      "cat36_cat40\n",
      "cat36_cat28\n",
      "cat36_cat111\n",
      "cat36_cat6\n",
      "cat36_cat76\n",
      "cat36_cat50\n",
      "cat36_cat5\n",
      "cat36_cat4\n",
      "cat36_cat14\n",
      "cat36_cat38\n",
      "cat36_cat24\n",
      "cat36_cat82\n",
      "cat36_cat25\n",
      "cat73_cat103\n",
      "cat73_cat40\n",
      "cat73_cat28\n",
      "cat73_cat111\n",
      "cat73_cat6\n",
      "cat73_cat76\n",
      "cat73_cat50\n",
      "cat73_cat5\n",
      "cat73_cat4\n",
      "cat73_cat14\n",
      "cat73_cat38\n",
      "cat73_cat24\n",
      "cat73_cat82\n",
      "cat73_cat25\n",
      "cat103_cat40\n",
      "cat103_cat28\n",
      "cat103_cat111\n",
      "cat103_cat6\n",
      "cat103_cat76\n",
      "cat103_cat50\n",
      "cat103_cat5\n",
      "cat103_cat4\n",
      "cat103_cat14\n",
      "cat103_cat38\n",
      "cat103_cat24\n",
      "cat103_cat82\n",
      "cat103_cat25\n",
      "cat40_cat28\n",
      "cat40_cat111\n",
      "cat40_cat6\n",
      "cat40_cat76\n",
      "cat40_cat50\n",
      "cat40_cat5\n",
      "cat40_cat4\n",
      "cat40_cat14\n",
      "cat40_cat38\n",
      "cat40_cat24\n",
      "cat40_cat82\n",
      "cat40_cat25\n",
      "cat28_cat111\n",
      "cat28_cat6\n",
      "cat28_cat76\n",
      "cat28_cat50\n",
      "cat28_cat5\n",
      "cat28_cat4\n",
      "cat28_cat14\n",
      "cat28_cat38\n",
      "cat28_cat24\n",
      "cat28_cat82\n",
      "cat28_cat25\n",
      "cat111_cat6\n",
      "cat111_cat76\n",
      "cat111_cat50\n",
      "cat111_cat5\n",
      "cat111_cat4\n",
      "cat111_cat14\n",
      "cat111_cat38\n",
      "cat111_cat24\n",
      "cat111_cat82\n",
      "cat111_cat25\n",
      "cat6_cat76\n",
      "cat6_cat50\n",
      "cat6_cat5\n",
      "cat6_cat4\n",
      "cat6_cat14\n",
      "cat6_cat38\n",
      "cat6_cat24\n",
      "cat6_cat82\n",
      "cat6_cat25\n",
      "cat76_cat50\n",
      "cat76_cat5\n",
      "cat76_cat4\n",
      "cat76_cat14\n",
      "cat76_cat38\n",
      "cat76_cat24\n",
      "cat76_cat82\n",
      "cat76_cat25\n",
      "cat50_cat5\n",
      "cat50_cat4\n",
      "cat50_cat14\n",
      "cat50_cat38\n",
      "cat50_cat24\n",
      "cat50_cat82\n",
      "cat50_cat25\n",
      "cat5_cat4\n",
      "cat5_cat14\n",
      "cat5_cat38\n",
      "cat5_cat24\n",
      "cat5_cat82\n",
      "cat5_cat25\n",
      "cat4_cat14\n",
      "cat4_cat38\n",
      "cat4_cat24\n",
      "cat4_cat82\n",
      "cat4_cat25\n",
      "cat14_cat38\n",
      "cat14_cat24\n",
      "cat14_cat82\n",
      "cat14_cat25\n",
      "cat38_cat24\n",
      "cat38_cat82\n",
      "cat38_cat25\n",
      "cat24_cat82\n",
      "cat24_cat25\n",
      "cat82_cat25\n"
     ]
    }
   ],
   "source": [
    "    for comb in itertools.combinations(COMB_FEATURE, 2):\n",
    "        feat = comb[0] + \"_\" + comb[1]\n",
    "        train_test[feat] = train_test[comb[0]] + train_test[comb[1]]\n",
    "        train_test[feat] = train_test[feat].apply(encode)\n",
    "        print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = [x for x in train.columns[1:-1] if 'cat' in x]\n",
    "for col in cats:\n",
    "    train_test[col] = train_test[col].apply(encode)\n",
    "train_test.loss = np.log(train_test.loss + shift)\n",
    "ss = StandardScaler()\n",
    "train_test[numeric_feats] = ss.fit_transform(train_test[numeric_feats].values)\n",
    "train = train_test.iloc[:ntrain, :].copy()\n",
    "test = train_test.iloc[ntrain:, :].copy()\n",
    "test.drop('loss', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Loss: 7.747411156506141\n",
      "Mean Loss: 7.799837008871419\n"
     ]
    }
   ],
   "source": [
    "print('Median Loss:', train.loss.median())\n",
    "print('Mean Loss:', train.loss.mean())\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.7,\n",
    "    'learning_rate': 0.03,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 12,\n",
    "    'min_child_weight': 100,\n",
    "    'booster': 'gbtree',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "[0]\ttrain-mae:3232.53\teval-mae:3236.54\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1547.94\teval-mae:1554.77\n",
      "[100]\ttrain-mae:1149.69\teval-mae:1187.93\n",
      "[150]\ttrain-mae:1100.82\teval-mae:1155.86\n",
      "[200]\ttrain-mae:1083.45\teval-mae:1148.51\n",
      "[250]\ttrain-mae:1070.96\teval-mae:1144.92\n",
      "[300]\ttrain-mae:1061.16\teval-mae:1142.34\n",
      "[350]\ttrain-mae:1052.27\teval-mae:1141.21\n",
      "[400]\ttrain-mae:1044.78\teval-mae:1140.04\n",
      "[450]\ttrain-mae:1036.95\teval-mae:1138.95\n",
      "[500]\ttrain-mae:1030.1\teval-mae:1138.05\n",
      "[550]\ttrain-mae:1022.53\teval-mae:1137.72\n",
      "[600]\ttrain-mae:1016.02\teval-mae:1137.09\n",
      "[650]\ttrain-mae:1009.98\teval-mae:1136.73\n",
      "Stopping. Best iteration:\n",
      "[653]\ttrain-mae:1009.78\teval-mae:1136.63\n",
      "\n",
      "Fold 2\n",
      "[0]\ttrain-mae:3231.37\teval-mae:3252.7\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1546.59\teval-mae:1568.39\n",
      "[100]\ttrain-mae:1150.71\teval-mae:1198.64\n",
      "[150]\ttrain-mae:1101.29\teval-mae:1161.82\n",
      "[200]\ttrain-mae:1084.29\teval-mae:1154.57\n",
      "[250]\ttrain-mae:1072.35\teval-mae:1150.4\n",
      "[300]\ttrain-mae:1062.78\teval-mae:1148.12\n",
      "[350]\ttrain-mae:1053.33\teval-mae:1147.03\n",
      "[400]\ttrain-mae:1045.35\teval-mae:1146.33\n",
      "[450]\ttrain-mae:1037.85\teval-mae:1145.56\n",
      "[500]\ttrain-mae:1031.03\teval-mae:1144.52\n",
      "[550]\ttrain-mae:1023.43\teval-mae:1144.01\n",
      "[600]\ttrain-mae:1017.08\teval-mae:1144.08\n",
      "Stopping. Best iteration:\n",
      "[575]\ttrain-mae:1019.87\teval-mae:1143.8\n",
      "\n",
      "Fold 3\n",
      "[0]\ttrain-mae:3235.53\teval-mae:3194.45\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1549.62\teval-mae:1517.95\n",
      "[100]\ttrain-mae:1152.4\teval-mae:1155.69\n",
      "[150]\ttrain-mae:1102.71\teval-mae:1126.33\n",
      "[200]\ttrain-mae:1084.89\teval-mae:1120.02\n",
      "[250]\ttrain-mae:1072.39\teval-mae:1116.57\n",
      "[300]\ttrain-mae:1063.17\teval-mae:1114.83\n",
      "[350]\ttrain-mae:1054.78\teval-mae:1113.44\n",
      "[400]\ttrain-mae:1046.44\teval-mae:1112.13\n",
      "[450]\ttrain-mae:1038.79\teval-mae:1111.04\n",
      "[500]\ttrain-mae:1032.17\teval-mae:1110.74\n",
      "Stopping. Best iteration:\n",
      "[501]\ttrain-mae:1032.03\teval-mae:1110.7\n",
      "\n",
      "Fold 4\n",
      "[0]\ttrain-mae:3233.81\teval-mae:3218.65\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1547.72\teval-mae:1557.35\n",
      "[100]\ttrain-mae:1151.13\teval-mae:1181.07\n",
      "[150]\ttrain-mae:1101.23\teval-mae:1145.38\n",
      "[200]\ttrain-mae:1083.54\teval-mae:1138.99\n",
      "[250]\ttrain-mae:1070.82\teval-mae:1135.79\n",
      "[300]\ttrain-mae:1061.37\teval-mae:1133.54\n",
      "[350]\ttrain-mae:1052.11\teval-mae:1132.01\n",
      "[400]\ttrain-mae:1044.43\teval-mae:1130.93\n",
      "[450]\ttrain-mae:1036.55\teval-mae:1129.88\n",
      "[500]\ttrain-mae:1030.32\teval-mae:1129.21\n",
      "[550]\ttrain-mae:1022.89\teval-mae:1128.49\n",
      "[600]\ttrain-mae:1016.9\teval-mae:1128.04\n",
      "[650]\ttrain-mae:1010.32\teval-mae:1127.52\n",
      "[700]\ttrain-mae:1004.19\teval-mae:1127.37\n",
      "Stopping. Best iteration:\n",
      "[676]\ttrain-mae:1006.98\teval-mae:1127.29\n",
      "\n",
      "Fold 5\n",
      "[0]\ttrain-mae:3231.4\teval-mae:3252.37\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1547.79\teval-mae:1564.96\n",
      "[100]\ttrain-mae:1151.76\teval-mae:1180.81\n",
      "[150]\ttrain-mae:1102.51\teval-mae:1143.63\n",
      "[200]\ttrain-mae:1084.27\teval-mae:1136.54\n",
      "[250]\ttrain-mae:1072.52\teval-mae:1133.41\n",
      "[300]\ttrain-mae:1062.95\teval-mae:1131.95\n",
      "[350]\ttrain-mae:1053.8\teval-mae:1130.29\n",
      "[400]\ttrain-mae:1045.58\teval-mae:1129.97\n",
      "[450]\ttrain-mae:1037.39\teval-mae:1129.53\n",
      "[500]\ttrain-mae:1030.49\teval-mae:1128.78\n",
      "[550]\ttrain-mae:1023.32\teval-mae:1128.12\n",
      "[600]\ttrain-mae:1016.78\teval-mae:1127.99\n",
      "Stopping. Best iteration:\n",
      "[600]\ttrain-mae:1016.78\teval-mae:1127.99\n",
      "\n",
      "Fold 6\n",
      "[0]\ttrain-mae:3232.97\teval-mae:3230.3\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1548.47\teval-mae:1553.56\n",
      "[100]\ttrain-mae:1152.19\teval-mae:1178.67\n",
      "[150]\ttrain-mae:1102.34\teval-mae:1139.23\n",
      "[200]\ttrain-mae:1084.95\teval-mae:1131.16\n",
      "[250]\ttrain-mae:1073.55\teval-mae:1128.01\n",
      "[300]\ttrain-mae:1063.01\teval-mae:1125.67\n",
      "[350]\ttrain-mae:1053.79\teval-mae:1124.23\n",
      "[400]\ttrain-mae:1045.03\teval-mae:1123.41\n",
      "[450]\ttrain-mae:1037.71\teval-mae:1122.77\n",
      "Stopping. Best iteration:\n",
      "[471]\ttrain-mae:1035.24\teval-mae:1122.5\n",
      "\n",
      "Fold 7\n",
      "[0]\ttrain-mae:3230.2\teval-mae:3269.14\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1547.1\teval-mae:1582.74\n",
      "[100]\ttrain-mae:1151.04\teval-mae:1203.8\n",
      "[150]\ttrain-mae:1100.53\teval-mae:1164.08\n",
      "[200]\ttrain-mae:1083.97\teval-mae:1155.91\n",
      "[250]\ttrain-mae:1071.66\teval-mae:1152.56\n",
      "[300]\ttrain-mae:1061.44\teval-mae:1150.11\n",
      "[350]\ttrain-mae:1052.71\teval-mae:1149.14\n",
      "[400]\ttrain-mae:1044.21\teval-mae:1147.81\n",
      "[450]\ttrain-mae:1036.33\teval-mae:1146.97\n",
      "Stopping. Best iteration:\n",
      "[457]\ttrain-mae:1035.52\teval-mae:1146.88\n",
      "\n",
      "Fold 8\n",
      "[0]\ttrain-mae:3232.71\teval-mae:3234.02\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1547.81\teval-mae:1575.4\n",
      "[100]\ttrain-mae:1149.77\teval-mae:1200.39\n",
      "[150]\ttrain-mae:1100.45\teval-mae:1162.36\n",
      "[200]\ttrain-mae:1082.95\teval-mae:1154.2\n",
      "[250]\ttrain-mae:1071.62\teval-mae:1150.18\n",
      "[300]\ttrain-mae:1061.46\teval-mae:1147.63\n",
      "[350]\ttrain-mae:1052.87\teval-mae:1145.86\n",
      "[400]\ttrain-mae:1045.19\teval-mae:1144.33\n",
      "[450]\ttrain-mae:1038.02\teval-mae:1142.97\n",
      "[500]\ttrain-mae:1030.75\teval-mae:1141.92\n",
      "[550]\ttrain-mae:1023.81\teval-mae:1141.18\n",
      "Stopping. Best iteration:\n",
      "[542]\ttrain-mae:1025.19\teval-mae:1141.05\n",
      "\n",
      "Fold 9\n",
      "[0]\ttrain-mae:3233.31\teval-mae:3225.58\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1548.93\teval-mae:1555.31\n",
      "[100]\ttrain-mae:1151.12\teval-mae:1183.01\n",
      "[150]\ttrain-mae:1101.58\teval-mae:1146.75\n",
      "[200]\ttrain-mae:1084.24\teval-mae:1139.76\n",
      "[250]\ttrain-mae:1073.38\teval-mae:1136.38\n",
      "[300]\ttrain-mae:1062.24\teval-mae:1134.17\n",
      "[350]\ttrain-mae:1053.36\teval-mae:1132.78\n",
      "[400]\ttrain-mae:1045.29\teval-mae:1131.37\n",
      "[450]\ttrain-mae:1038\teval-mae:1130.36\n",
      "[500]\ttrain-mae:1030.98\teval-mae:1129.66\n",
      "[550]\ttrain-mae:1024.5\teval-mae:1128.76\n",
      "[600]\ttrain-mae:1017.97\teval-mae:1128.41\n",
      "Stopping. Best iteration:\n",
      "[605]\ttrain-mae:1017.29\teval-mae:1128.24\n",
      "\n",
      "Fold 10\n",
      "[0]\ttrain-mae:3232.34\teval-mae:3239.11\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1546.86\teval-mae:1563.93\n",
      "[100]\ttrain-mae:1149.45\teval-mae:1189.07\n",
      "[150]\ttrain-mae:1100.3\teval-mae:1151.28\n",
      "[200]\ttrain-mae:1083.24\teval-mae:1143.78\n",
      "[250]\ttrain-mae:1072.12\teval-mae:1140.62\n",
      "[300]\ttrain-mae:1061.85\teval-mae:1138.42\n",
      "[350]\ttrain-mae:1052.76\teval-mae:1136.92\n",
      "[400]\ttrain-mae:1044.35\teval-mae:1135.63\n",
      "[450]\ttrain-mae:1037.16\teval-mae:1134.86\n",
      "Stopping. Best iteration:\n",
      "[428]\ttrain-mae:1040.38\teval-mae:1134.82\n",
      "\n",
      "Fold 11\n",
      "[0]\ttrain-mae:3232.46\teval-mae:3237.41\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1547.87\teval-mae:1555.65\n",
      "[100]\ttrain-mae:1150.33\teval-mae:1179.7\n",
      "[150]\ttrain-mae:1101.29\teval-mae:1146.3\n",
      "[200]\ttrain-mae:1084.34\teval-mae:1139.9\n",
      "[250]\ttrain-mae:1072.67\teval-mae:1136.76\n",
      "[300]\ttrain-mae:1062.62\teval-mae:1134.23\n",
      "[350]\ttrain-mae:1053.56\teval-mae:1132.64\n",
      "[400]\ttrain-mae:1045.16\teval-mae:1130.93\n",
      "[450]\ttrain-mae:1038.16\teval-mae:1130.22\n",
      "Stopping. Best iteration:\n",
      "[430]\ttrain-mae:1040.7\teval-mae:1130.06\n",
      "\n",
      "Fold 12\n",
      "[0]\ttrain-mae:3232.57\teval-mae:3236\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1547.47\teval-mae:1569.49\n",
      "[100]\ttrain-mae:1149.24\teval-mae:1197.67\n",
      "[150]\ttrain-mae:1100.27\teval-mae:1161.98\n",
      "[200]\ttrain-mae:1083.34\teval-mae:1154.88\n",
      "[250]\ttrain-mae:1071.61\teval-mae:1152.28\n",
      "[300]\ttrain-mae:1062.41\teval-mae:1150.63\n",
      "[350]\ttrain-mae:1053.62\teval-mae:1150.06\n",
      "[400]\ttrain-mae:1045.23\teval-mae:1148.95\n",
      "[450]\ttrain-mae:1037.65\teval-mae:1148.06\n",
      "[500]\ttrain-mae:1030.17\teval-mae:1147.39\n",
      "[550]\ttrain-mae:1022.65\teval-mae:1146.48\n",
      "Stopping. Best iteration:\n",
      "[573]\ttrain-mae:1019.63\teval-mae:1146.16\n",
      "\n",
      "Fold 13\n",
      "[0]\ttrain-mae:3232.03\teval-mae:3243.52\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1547.81\teval-mae:1565.26\n",
      "[100]\ttrain-mae:1151.23\teval-mae:1187.88\n",
      "[150]\ttrain-mae:1101.01\teval-mae:1150.15\n",
      "[200]\ttrain-mae:1084.41\teval-mae:1142.56\n",
      "[250]\ttrain-mae:1071.79\teval-mae:1138.49\n",
      "[300]\ttrain-mae:1061.6\teval-mae:1135.65\n",
      "[350]\ttrain-mae:1053.19\teval-mae:1134.47\n",
      "[400]\ttrain-mae:1044.81\teval-mae:1132.88\n",
      "[450]\ttrain-mae:1036.68\teval-mae:1131.2\n",
      "[500]\ttrain-mae:1029.54\teval-mae:1130.61\n",
      "[550]\ttrain-mae:1022.51\teval-mae:1129.74\n",
      "[600]\ttrain-mae:1015.67\teval-mae:1129.4\n",
      "Stopping. Best iteration:\n",
      "[593]\ttrain-mae:1016.44\teval-mae:1129.28\n",
      "\n",
      "Fold 14\n",
      "[0]\ttrain-mae:3235.13\teval-mae:3200.16\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1550.49\teval-mae:1527.78\n",
      "[100]\ttrain-mae:1151.45\teval-mae:1155.37\n",
      "[150]\ttrain-mae:1101.67\teval-mae:1121.33\n",
      "[200]\ttrain-mae:1084.4\teval-mae:1114.99\n",
      "[250]\ttrain-mae:1072.54\teval-mae:1112.25\n",
      "[300]\ttrain-mae:1063.17\teval-mae:1110.57\n",
      "[350]\ttrain-mae:1054.26\teval-mae:1109.52\n",
      "[400]\ttrain-mae:1046.01\teval-mae:1108.94\n",
      "[450]\ttrain-mae:1038.52\teval-mae:1108.71\n",
      "Stopping. Best iteration:\n",
      "[429]\ttrain-mae:1041.15\teval-mae:1108.53\n",
      "\n",
      "Fold 15\n",
      "[0]\ttrain-mae:3233.57\teval-mae:3221.98\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 25 rounds.\n",
      "[50]\ttrain-mae:1547.55\teval-mae:1556.2\n",
      "[100]\ttrain-mae:1149.96\teval-mae:1182.79\n",
      "[150]\ttrain-mae:1100.66\teval-mae:1148.11\n",
      "[200]\ttrain-mae:1083.41\teval-mae:1139.87\n",
      "[250]\ttrain-mae:1071.77\teval-mae:1135.98\n",
      "[300]\ttrain-mae:1062.18\teval-mae:1133.54\n",
      "[350]\ttrain-mae:1053.66\teval-mae:1131.52\n",
      "[400]\ttrain-mae:1045.73\teval-mae:1130.59\n",
      "[450]\ttrain-mae:1038.66\teval-mae:1129.76\n",
      "[500]\ttrain-mae:1031.57\teval-mae:1129.08\n",
      "[550]\ttrain-mae:1024.43\teval-mae:1128.2\n",
      "Stopping. Best iteration:\n",
      "[564]\ttrain-mae:1022.57\teval-mae:1128.02\n",
      "\n",
      "         p0        p1        p2        p3        p4        p5        p6  \\\n",
      "0  7.470220  7.485849  7.539794  7.491741  7.452842  7.503007  7.502959   \n",
      "1  7.691556  7.694995  7.699736  7.665207  7.672572  7.640437  7.631391   \n",
      "2  9.253429  9.220746  9.189989  9.140989  9.175927  9.203345  9.217809   \n",
      "3  8.790034  8.742352  8.795990  8.815215  8.845306  8.799650  8.752242   \n",
      "4  6.891798  6.853507  6.901651  6.891091  6.886682  6.897743  6.878188   \n",
      "\n",
      "         p7        p8        p9       p10       p11       p12       p13  \\\n",
      "0  7.453992  7.426644  7.501616  7.491080  7.478284  7.504318  7.492102   \n",
      "1  7.650261  7.610249  7.631194  7.707417  7.684087  7.696122  7.627191   \n",
      "2  9.066344  9.194108  9.204820  9.181361  9.162892  9.209412  9.235514   \n",
      "3  8.811095  8.801686  8.820447  8.785161  8.803964  8.808388  8.887237   \n",
      "4  6.918854  6.858478  6.908374  6.905556  6.904885  6.904188  6.869956   \n",
      "\n",
      "        p14  \n",
      "0  7.467395  \n",
      "1  7.791390  \n",
      "2  9.163079  \n",
      "3  8.897757  \n",
      "4  6.899100  \n"
     ]
    }
   ],
   "source": [
    "best_nrounds = 20000  # 640 score from above commented out code (Faron)\n",
    "allpredictions = pd.DataFrame()\n",
    "kfolds = 15  # 10 folds is better!\n",
    "\n",
    "if kfolds > 1:\n",
    "    kf = KFold(n_splits=kfolds)\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "        dtest = xgb.DMatrix(test[test.columns[1:]])\n",
    "        print('Fold {0}'.format(i + 1))\n",
    "        X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n",
    "        cols_ = [x for x in X_train.columns if 'loss' not in x][1:]\n",
    "        dtrain = xgb.DMatrix(X_train[cols_], label=X_train.loss)\n",
    "        dvalid = xgb.DMatrix(X_val[cols_], label=X_val.loss)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "\n",
    "        gbdt = xgb.train(xgb_params, dtrain, best_nrounds, watchlist,\n",
    "                        obj=logregobj,\n",
    "                        feval=xg_eval_mae, maximize=False,\n",
    "                        verbose_eval=50,\n",
    "                        early_stopping_rounds=25)\n",
    "        del dtrain\n",
    "        del dvalid\n",
    "        gc.collect()\n",
    "        allpredictions['p' + str(i)] = gbdt.predict(dtest, ntree_limit=gbdt.best_ntree_limit)\n",
    "        del dtest\n",
    "        del gbdt\n",
    "        gc.collect()\n",
    "        \n",
    "else:\n",
    "    cols_ = [x for x in train.columns if 'loss' not in x][1:]\n",
    "\n",
    "    dtest = xgb.DMatrix(test[cols_].values)\n",
    "    dtrain = xgb.DMatrix(train[cols_].values, label=train.loss)\n",
    "    watchlist = [(dtrain, 'train'), (dtrain, 'eval')]\n",
    "    gbdt = xgb.train(xgb_params, dtrain, best_nrounds, watchlist,\n",
    "                    obj=logregobj,\n",
    "                    feval=xg_eval_mae, maximize=False,\n",
    "                    verbose_eval=50, early_stopping_rounds=25)\n",
    "    \n",
    "    allpredictions['p1'] = gbdt.predict(dtest, ntree_limit=gbdt.best_ntree_limit)\n",
    "    del dtrain\n",
    "    del dtest\n",
    "    del gbdt\n",
    "    gc.collect()\n",
    "\n",
    "print(allpredictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(r'D:\\allstate\\sample_submission.csv.zip')\n",
    "if (kfolds > 1):\n",
    "    submission.iloc[:, 1] = np.exp(allpredictions.mean(axis=1).values) - shift\n",
    "    submission.to_csv('xgbmeansubmission2.csv', index=None)\n",
    "    submission.iloc[:, 1] = np.exp(allpredictions.median(axis=1).values) - shift\n",
    "    submission.to_csv('xgbmediansubmission2.csv', index=None)\n",
    "else:\n",
    "    submission.iloc[:, 1] = np.exp(allpredictions.p1.values) - shift\n",
    "    submission.to_csv('xgbsubmission2.csv', index=None)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
